# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a Korean e-commerce review analysis tool that crawls product reviews from Naver Smart Store and performs sentiment analysis and topic modeling. The application uses web scraping techniques to gather review data and applies natural language processing to extract insights from Korean text.

## Development Commands

### Setup and Installation
```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment (Windows)
venv\Scripts\activate

# Activate virtual environment (macOS/Linux)
source venv/bin/activate

# Install required dependencies
pip install requests pandas konlpy scikit-learn
```

### Running the Application
```bash
# Run the basic analysis script (ìˆ˜ì •ëœ ë²„ì „)
python main.py

# Run the advanced stealth crawler (ê°€ì¥ ê°•ë ¥í•œ ìš°íšŒ ê¸°ëŠ¥)
python stealth_crawler.py

# Run the Selenium browser automation crawler
python selenium_crawler.py

# Run the mobile API crawler 
python mobile_crawler.py

# ğŸ†• NEW: Smart Scheduler (ìë™ URL íŒŒì‹± + ìŠ¤ì¼€ì¤„ë§ + VPN)
python smart_scheduler.py

# ğŸ†• Quick Start (URLë§Œ ì…ë ¥í•˜ë©´ ë°”ë¡œ í¬ë¡¤ë§)
python quick_start.py

# ğŸ–¥ï¸ NEW: GUI ì¸í„°í˜ì´ìŠ¤ (í´ë¦­ í•œë²ˆìœ¼ë¡œ í¬ë¡¤ë§!)
python web_gui.py          # ì›¹ GUI (ë¸Œë¼ìš°ì €)
python desktop_gui.py      # ë°ìŠ¤í¬í†± GUI (ìœˆë„ìš° í”„ë¡œê·¸ë¨)

# ğŸ“¦ NEW: EXE íŒŒì¼ ìƒì„± (ì„¤ì¹˜ ì—†ì´ ì‹¤í–‰)
python build_exe.py        # EXE íŒŒì¼ ë¹Œë“œ

# All scripts will output results to different CSV files
```

## Code Architecture

### Core Components

#### Data Collection (`main.py:14-93`)
- **Review Crawling**: Uses Naver Smart Store API endpoints to fetch product reviews
- **Product Information Retrieval**: Extracts merchant and product IDs from product summary API
- **Pagination Handling**: Iterates through review pages until no more reviews are available
- **Rate Limiting**: Implements 1-second delays between requests to avoid rate limiting

#### Text Processing Pipeline (`main.py:97-146`)
- **Sentiment Analysis**: Keyword-based sentiment classification using predefined positive/negative word lists
- **Topic Modeling**: Uses Latent Dirichlet Allocation (LDA) with TF-IDF vectorization for topic extraction
- **Korean Text Processing**: Leverages KoNLPy's Okt tokenizer for Korean noun extraction

#### Configuration (`main.py:9-12`)
- **PRODUCT_ID**: Target product identifier for analysis
- **OUTPUT_FILE_NAME**: CSV output file name
- **NUM_TOPICS**: Number of topics for LDA clustering

### Data Flow

1. **Product Information Retrieval**: Fetches merchant and origin product numbers from summary API
2. **Review Collection**: Paginated crawling of reviews with comprehensive metadata
3. **Text Processing**: Korean text tokenization and cleaning
4. **Sentiment Classification**: Rule-based sentiment scoring using keyword matching
5. **Topic Extraction**: LDA-based topic modeling on processed review text
6. **Output Generation**: CSV export with enriched review data including sentiment and topic assignments

### API Integration

The application interacts with Naver Smart Store's internal APIs:
- **Product Summary API**: `https://smartstore.naver.com/i/v1/products/{product_id}/summary`
- **Reviews API**: `https://smartstore.naver.com/main/products/{origin_product_no}/reviews/writable-reviews`

Headers include User-Agent and Referer to mimic browser requests and avoid detection.

## Anti-Detection Features

### Advanced Crawler (`advanced_crawler.py`)
The advanced version includes sophisticated anti-detection mechanisms:

- **Dynamic User-Agent Rotation**: 12+ realistic browser user agents with proper header combinations
- **Intelligent Delay System**: Adaptive request timing based on response patterns and request count
- **Session Fingerprinting**: Simulates real browser behavior with preliminary page visits
- **Retry Strategy**: Exponential backoff with circuit breaker patterns for different error types
- **Proxy Support**: Ready for proxy rotation (configure PROXIES list)
- **Enhanced Error Handling**: Detailed status code analysis with appropriate recovery strategies

### Rate Limiting Countermeasures
- **Progressive Delays**: 1-3s initial, 2-5s moderate, 3-8s heavy traffic
- **Failure Recovery**: Up to 5 retry attempts with exponential backoff
- **Circuit Breaker**: Automatic suspension after 3 consecutive failures
- **Long-term Blocks**: 5-10 minute delays for 403 responses

## Key Dependencies

- **requests**: HTTP client for API communication
- **pandas**: Data manipulation and CSV export
- **konlpy**: Korean language processing (Okt tokenizer)
- **scikit-learn**: Machine learning tools (TF-IDF, LDA)
- **urllib3**: Advanced HTTP features and SSL handling

## Configuration Notes

To analyze a different product, modify the `PRODUCT_ID` constant in either script. The sentiment analysis keywords can be customized by editing the positive_keywords and negative_keywords lists.

## í¬ë¡¤ëŸ¬ ì„ íƒ ê°€ì´ë“œ

### 1. **stealth_crawler.py** (ê°€ì¥ ê¶Œì¥)
- **ì¥ì **: ê°€ì¥ ê°•ë ¥í•œ IP ì°¨ë‹¨ ìš°íšŒ ê¸°ëŠ¥
- **íŠ¹ì§•**: 15ë²ˆ ì¬ì‹œë„, ì¸ê°„ í–‰ë™ ì‹œë®¬ë ˆì´ì…˜, ê·¹ë„ë¡œ ì •êµí•œ ì§€ì—°
- **ì‚¬ìš© ì‹œê¸°**: ë‹¤ë¥¸ ëª¨ë“  ë°©ë²•ì´ ì‹¤íŒ¨í–ˆì„ ë•Œ

### 2. **selenium_crawler.py** (ë†’ì€ ì„±ê³µë¥ )
- **ì¥ì **: ì‹¤ì œ ë¸Œë¼ìš°ì € ì‚¬ìš©ìœ¼ë¡œ íƒì§€ ì–´ë ¤ì›€
- **íŠ¹ì§•**: Chrome ë¸Œë¼ìš°ì € ìë™í™”, ë´‡ íƒì§€ ìš°íšŒ
- **ì‚¬ìš© ì‹œê¸°**: GUI í™˜ê²½ì—ì„œ ì•ˆì •ì ì¸ í¬ë¡¤ë§ í•„ìš”ì‹œ
- **ìš”êµ¬ì‚¬í•­**: Chrome ë¸Œë¼ìš°ì € + ChromeDriver ì„¤ì¹˜

### 3. **mobile_crawler.py** (ì°¨ë³„í™”ëœ ì ‘ê·¼)
- **ì¥ì **: ëª¨ë°”ì¼ API ì—”ë“œí¬ì¸íŠ¸ í™œìš©
- **íŠ¹ì§•**: ì•± ì‹œë®¬ë ˆì´ì…˜, ë‹¤ì–‘í•œ ëª¨ë°”ì¼ User-Agent
- **ì‚¬ìš© ì‹œê¸°**: ë°ìŠ¤í¬í†± APIê°€ ì°¨ë‹¨ëœ ê²½ìš°

### 4. **advanced_crawler.py** (ê¸°ë³¸ ê³ ê¸‰ ë²„ì „)
- **ì¥ì **: í–¥ìƒëœ ìš°íšŒ ê¸°ëŠ¥
- **íŠ¹ì§•**: ë™ì  í—¤ë”, ì¬ì‹œë„ ë¡œì§, í”„ë¡ì‹œ ì§€ì›
- **ì‚¬ìš© ì‹œê¸°**: ê¸°ë³¸ í¬ë¡¤ë§ ì‹¤íŒ¨ì‹œ ì²« ë²ˆì§¸ ëŒ€ì•ˆ

### 5. **main.py** (ê¸°ë³¸ ë²„ì „)
- **ì¥ì **: ê°€ë³ê³  ë¹ ë¦„
- **íŠ¹ì§•**: ê¸°ë³¸ì ì¸ ìš°íšŒ ê¸°ëŠ¥ë§Œ í¬í•¨
- **ì‚¬ìš© ì‹œê¸°**: IP ì°¨ë‹¨ì´ ì—†ê±°ë‚˜ í…ŒìŠ¤íŠ¸ìš©

## ì„±ê³µë¥  í–¥ìƒ íŒ

### ê¶Œì¥ ì‹¤í–‰ ìˆœì„œ
1. `stealth_crawler.py` (ê°€ì¥ ë†’ì€ ì„±ê³µë¥ )
2. `selenium_crawler.py` (ë¸Œë¼ìš°ì € ìë™í™”)
3. `mobile_crawler.py` (ëª¨ë°”ì¼ API)
4. `advanced_crawler.py` (í–¥ìƒëœ ê¸°ë³¸)
5. `main.py` (ê¸°ë³¸ ë²„ì „)

### ìµœì  ì‹¤í–‰ í™˜ê²½
- **ì‹œê°„**: í•œêµ­ ì‹œê°„ ìƒˆë²½ 2-6ì‹œ (íŠ¸ë˜í”½ ìµœì†Œ)
- **ë„¤íŠ¸ì›Œí¬**: VPN ë˜ëŠ” í”„ë¡ì‹œ ì‚¬ìš© ê¶Œì¥
- **ë¹ˆë„**: ê°™ì€ ìƒí’ˆë‹¹ í•˜ë£¨ 1-2íšŒ ì œí•œ
- **ì¸ë‚´ì‹¬**: stealth_crawlerëŠ” ë§¤ìš° ëŠë¦¬ê²Œ ì‘ë™ (ì•ˆì „ì„±ì„ ìœ„í•´)

### ì¶”ê°€ ì„¤ì •
- í”„ë¡ì‹œ ì„œë²„ê°€ ìˆë‹¤ë©´ ê° í¬ë¡¤ëŸ¬ì˜ PROXIES ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
- Selenium ì‚¬ìš©ì‹œ Chrome ë¸Œë¼ìš°ì €ì™€ ChromeDriver í•„ìš”
- ì¥ì‹œê°„ ì‹¤í–‰ì‹œ ì¤‘ê°„ì— ì¤‘ë‹¨ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—¬ëŸ¬ ë²ˆ ë‚˜ëˆ„ì–´ ì‹¤í–‰ ê¶Œì¥

## ğŸ†• ìŠ¤ë§ˆíŠ¸ ìŠ¤ì¼€ì¤„ëŸ¬ (NEW!)

### ì£¼ìš” ê¸°ëŠ¥
- **URL ìë™ íŒŒì‹±**: ìƒí’ˆ í˜ì´ì§€ URLì—ì„œ ìƒí’ˆ ID ìë™ ì¶”ì¶œ
- **ìë™ ìŠ¤ì¼€ì¤„ë§**: ì •í•´ì§„ ì‹œê°„(ìƒˆë²½ 2ì‹œ, 3ì‹œ 30ë¶„, 5ì‹œ)ì— ìë™ ì‹¤í–‰
- **VPN ìë™ ê´€ë¦¬**: ExpressVPN, NordVPN, SurfShark ì§€ì›
- **ë‹¤ì¤‘ í¬ë¡¤ëŸ¬ í†µí•©**: ì‹¤íŒ¨ì‹œ ìë™ìœ¼ë¡œ ë‹¤ìŒ í¬ë¡¤ëŸ¬ ì‹œë„
- **ì„¤ì • íŒŒì¼ ê´€ë¦¬**: JSON ê¸°ë°˜ ì˜êµ¬ ì„¤ì • ì €ì¥
- **ìƒì„¸í•œ ë¡œê·¸**: ì„±ê³µ/ì‹¤íŒ¨ ì¶”ì  ë° ë¶„ì„

### ë¹ ë¥¸ ì‹œì‘

#### 1. ì¦‰ì‹œ í¬ë¡¤ë§
```bash
# URLë§Œ ì…ë ¥í•˜ë©´ ë°”ë¡œ í¬ë¡¤ë§
python quick_start.py

# ë˜ëŠ” ëª…ë ¹í–‰ì—ì„œ ì§ì ‘
python quick_start.py "https://smartstore.naver.com/store/products/12345678"
```

#### 2. ìë™ ìŠ¤ì¼€ì¤„ë§ ì„¤ì •
```bash
# ëŒ€í™”í˜• ì„¤ì •
python smart_scheduler.py

# ë©”ë‰´ì—ì„œ ì„ íƒ:
# 1. ìƒí’ˆ ì¶”ê°€ (URL ì…ë ¥)
# 2. VPN ì„¤ì • 
# 3. ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
```

### ì§€ì›í•˜ëŠ” URL í˜•ì‹
- `https://smartstore.naver.com/store/products/12345678`
- `https://shopping.naver.com/products/12345678`
- `https://m.smartstore.naver.com/store/products/12345678`
- `https://shopping.naver.com/search?query=ìƒí’ˆ&nvMid=12345678`

### VPN ì„¤ì • ì˜ˆì œ
```bash
# ExpressVPN
expressvpn connect japan

# NordVPN  
nordvpn connect japan

# SurfShark
surfshark-vpn attack japan
```

### ì„¤ì • íŒŒì¼ (crawler_config.json)
```json
{
  "schedule": {
    "auto_run_times": ["02:00", "03:30", "05:00"]
  },
  "vpn": {
    "enabled": true,
    "provider": "expressvpn",
    "countries": ["japan", "singapore", "australia"]
  },
  "crawlers": {
    "priority_order": ["stealth", "selenium", "mobile", "advanced"]
  }
}
```

### ìë™í™” ì›Œí¬í”Œë¡œìš°
1. **ìƒí’ˆ ë“±ë¡**: URL ì…ë ¥ â†’ ìë™ ìƒí’ˆ ID ì¶”ì¶œ
2. **ìŠ¤ì¼€ì¤„ ì‹¤í–‰**: ì„¤ì •ëœ ì‹œê°„ì— ìë™ ì‹œì‘
3. **VPN ì—°ê²°**: ëœë¤ êµ­ê°€ ì„œë²„ë¡œ ìë™ ì—°ê²°
4. **í¬ë¡¤ë§ ì‹œë„**: ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ í¬ë¡¤ëŸ¬ ì‹¤í–‰
5. **ê²°ê³¼ ì €ì¥**: íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ CSV íŒŒì¼ ìƒì„±
6. **VPN í•´ì œ**: í¬ë¡¤ë§ ì™„ë£Œ í›„ ìë™ ì—°ê²° í•´ì œ
7. **ë¡œê·¸ ê¸°ë¡**: ì„±ê³µ/ì‹¤íŒ¨ í†µê³„ ì—…ë°ì´íŠ¸

### ì¶œë ¥ íŒŒì¼ í˜•ì‹
```
crawl_results/
â”œâ”€â”€ 12345678_20240123_143022_stealth.csv
â”œâ”€â”€ 87654321_20240123_143532_selenium.csv
â””â”€â”€ logs/
    â””â”€â”€ crawler_scheduler_20240123.log
```

## ğŸ–¥ï¸ GUI ì¸í„°í˜ì´ìŠ¤ (NEW!)

### ì›¹ GUI (ì¶”ì²œ)
```bash
# ì›¹ ì„œë²„ ì‹œì‘
python web_gui.py

# ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†
http://localhost:5000
```

**íŠ¹ì§•:**
- ğŸŒ **ë¸Œë¼ìš°ì € ê¸°ë°˜**: Chrome, Safari, Firefox ë“± ëª¨ë“  ë¸Œë¼ìš°ì €
- ğŸ“± **ëª¨ë°”ì¼ ì§€ì›**: ìŠ¤ë§ˆíŠ¸í°, íƒœë¸”ë¦¿ì—ì„œë„ ì‚¬ìš© ê°€ëŠ¥
- ğŸ¨ **ëª¨ë˜ ë””ìì¸**: Bootstrap ê¸°ë°˜ ë°˜ì‘í˜• UI
- âš¡ **ì‹¤ì‹œê°„ ì§„í–‰ë¥ **: í¬ë¡¤ë§ ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ í‘œì‹œ
- ğŸ“Š **ëŒ€ì‹œë³´ë“œ**: ìƒí’ˆ ê´€ë¦¬, ì„¤ì •, í†µê³„ í•œëˆˆì— ë³´ê¸°

### ë°ìŠ¤í¬í†± GUI
```bash
# ìœˆë„ìš° í”„ë¡œê·¸ë¨ì²˜ëŸ¼ ì‹¤í–‰
python desktop_gui.py
```

**íŠ¹ì§•:**
- ğŸ–¥ï¸ **ë„¤ì´í‹°ë¸Œ ì•±**: Windows í”„ë¡œê·¸ë¨ì²˜ëŸ¼ ë™ì‘
- ğŸ›ï¸ **ë‹¤ì¤‘ íƒ­**: í¬ë¡¤ë§, ìƒí’ˆê´€ë¦¬, ì„¤ì •, ë¡œê·¸
- ğŸ“‹ **ì¼ê´„ ì²˜ë¦¬**: ì—¬ëŸ¬ ìƒí’ˆ ë™ì‹œ í¬ë¡¤ë§
- ğŸ’¾ **ë¡œê·¸ ì €ì¥**: ëª¨ë“  ê³¼ì •ì„ íŒŒì¼ë¡œ ì €ì¥
- ğŸ”§ **ê³ ê¸‰ ì„¤ì •**: ì„¸ë°€í•œ ì˜µì…˜ ì¡°ì •

### EXE íŒŒì¼ (ë°°í¬ìš©)
```bash
# EXE íŒŒì¼ ë¹Œë“œ
python build_exe.py

# ìƒì„±ëœ íŒŒì¼ ì‹¤í–‰ (Python ì„¤ì¹˜ ë¶ˆí•„ìš”)
dist/NaverSmartCrawler.exe
```

**íŠ¹ì§•:**
- ğŸ“¦ **ë…ë¦½ì‹¤í–‰**: Python ì„¤ì¹˜ ì—†ì´ ì‹¤í–‰ ê°€ëŠ¥
- ğŸš€ **ê°„í¸ë°°í¬**: ë‹¤ë¥¸ ì»´í“¨í„°ì—ì„œë„ ë°”ë¡œ ì‹¤í–‰
- ğŸ’» **Windows í˜¸í™˜**: Windows 7/10/11 ì§€ì›
- ğŸ“ **ì™„ì „íŒ¨í‚¤ì§€**: ëª¨ë“  ì˜ì¡´ì„± í¬í•¨

### GUI ê¸°ëŠ¥ ë¹„êµ

| ê¸°ëŠ¥ | ì›¹ GUI | ë°ìŠ¤í¬í†± GUI | EXE íŒŒì¼ |
|------|--------|--------------|----------|
| ì„¤ì¹˜ ë³µì¡ë„ | ì‰¬ì›€ | ì¤‘ê°„ | ë§¤ìš° ì‰¬ì›€ |
| ì ‘ê·¼ì„± | ëª¨ë“  ê¸°ê¸° | ë¡œì»¬ë§Œ | ë¡œì»¬ë§Œ |
| ì„±ëŠ¥ | ì¤‘ê°„ | ë¹ ë¦„ | ë¹ ë¦„ |
| ì—…ë°ì´íŠ¸ | ì‰¬ì›€ | ì¤‘ê°„ | ì–´ë ¤ì›€ |
| ë°°í¬ | ì–´ë ¤ì›€ | ì–´ë ¤ì›€ | ë§¤ìš° ì‰¬ì›€ |

### ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

#### ğŸ  ê°œì¸ ì‚¬ìš©ì
```bash
# ê°„ë‹¨í•œ í¬ë¡¤ë§
python web_gui.py
# â†’ ë¸Œë¼ìš°ì €ì—ì„œ URL ì…ë ¥í•˜ê³  í´ë¦­
```

#### ğŸ¢ ì‚¬ë¬´ì‹¤ í™˜ê²½
```bash
# ì—¬ëŸ¬ ì§ì›ì´ ê³µìœ 
python web_gui.py
# â†’ ê°ì ë¸Œë¼ìš°ì €ì—ì„œ http://ì„œë²„IP:5000 ì ‘ì†
```

#### ğŸ“¦ ì™¸ë¶€ ë°°í¬
```bash
# EXE íŒŒì¼ ìƒì„± í›„ USBë¡œ ì „ë‹¬
python build_exe.py
# â†’ dist í´ë”ë¥¼ ë‹¤ë¥¸ PCì— ë³µì‚¬
```

### GUI ì¥ì 

#### âœ¨ ì‚¬ìš©ì ì¹œí™”ì 
- **ì§ê´€ì  ì¸í„°í˜ì´ìŠ¤**: í´ë¦­ë§Œìœ¼ë¡œ ëª¨ë“  ê¸°ëŠ¥ ì‚¬ìš©
- **ì‹¤ì‹œê°„ í”¼ë“œë°±**: ì§„í–‰ ìƒí™©ê³¼ ê²°ê³¼ ì¦‰ì‹œ í™•ì¸
- **ì˜¤ë¥˜ ì•Œë¦¼**: ë¬¸ì œ ë°œìƒì‹œ ì¹œì ˆí•œ ì•ˆë‚´ ë©”ì‹œì§€

#### ğŸš€ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
- **ì›í´ë¦­ í¬ë¡¤ë§**: URL ë¶™ì—¬ë„£ê¸° â†’ í´ë¦­ â†’ ì™„ë£Œ
- **ì¼ê´„ ì²˜ë¦¬**: ì—¬ëŸ¬ ìƒí’ˆì„ í•œë²ˆì— í¬ë¡¤ë§
- **ìë™ ì¬ì‹œë„**: ì‹¤íŒ¨ì‹œ ë‹¤ë¥¸ í¬ë¡¤ëŸ¬ë¡œ ìë™ ì „í™˜

#### ğŸ”§ ê³ ê¸‰ ê¸°ëŠ¥
- **VPN í†µí•©**: GUIì—ì„œ ë°”ë¡œ VPN ì„¤ì • ë° ì—°ê²°
- **ìŠ¤ì¼€ì¤„ë§**: ì›í•˜ëŠ” ì‹œê°„ì— ìë™ ì‹¤í–‰ ì„¤ì •
- **ê²°ê³¼ ë¶„ì„**: í¬ë¡¤ë§ ê²°ê³¼ë¥¼ ì°¨íŠ¸ì™€ í‘œë¡œ ì‹œê°í™”