"""
ëª¨ë°”ì¼ API ê¸°ë°˜ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ë¦¬ë·° í¬ë¡¤ëŸ¬
ëª¨ë°”ì¼ ì•± API ì—”ë“œí¬ì¸íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ì°¨ë‹¨ ìš°íšŒ
"""
import requests
import pandas as pd
import json
import time
import random
import uuid
import re
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from urllib3.exceptions import InsecureRequestWarning
from analysis import analyze_sentiment, topic_modeling

requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

# --- ì„¤ì • ë¶€ë¶„ ---
PRODUCT_ID = "5753732771"
OUTPUT_FILE_NAME = "reviews_mobile.csv"
NUM_TOPICS = 5

MOBILE_USER_AGENTS = [
    "Mozilla/5.0 (Linux; Android 14; SM-S918B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Mobile Safari/537.36",
    "Mozilla/5.0 (iPhone; CPU iPhone OS 17_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Mobile/15E148 Safari/604.1",
]

MOBILE_ENDPOINTS = {
    'product_summary': 'https://m.smartstore.naver.com/api/products/{product_id}/summary',
    'reviews_v1': 'https://m.smartstore.naver.com/api/products/{product_id}/reviews',
    'reviews_v2': 'https://shopping.naver.com/v1/products/{product_id}/reviews',
}

class MobileNaverCrawler:
    def __init__(self, product_id):
        self.product_id = product_id
        self.session = self._create_mobile_session()
        self.request_count = 0
        
    def _create_mobile_session(self):
        session = requests.Session()
        retry_strategy = Retry(
            total=8, backoff_factor=2,
            status_forcelist=[403, 429, 500, 502, 503, 504],
            allowed_methods=["GET", "POST"]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy, pool_connections=15, pool_maxsize=30)
        session.mount("https://", adapter)
        session.verify = False
        return session
    
    def _get_mobile_headers(self, referer_url=None):
        headers = {
            "User-Agent": random.choice(MOBILE_USER_AGENTS),
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "ko-KR,ko;q=0.9",
            "Referer": referer_url or f"https://m.smartstore.naver.com/products/{self.product_id}",
        }
        return headers

    def _mobile_delay(self):
        delay = random.uniform(1.5, 4.0)
        print(f"ğŸ“± {delay:.2f}ì´ˆ ëŒ€ê¸°...")
        time.sleep(delay)
        self.request_count += 1
    
    def get_product_info_mobile(self):
        print("ğŸ“± ëª¨ë°”ì¼ APIë¡œ ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
        url = MOBILE_ENDPOINTS['product_summary'].format(product_id=self.product_id)
        try:
            response = self.session.get(url, headers=self._get_mobile_headers(), timeout=20)
            response.raise_for_status()
            data = response.json()
            
            product_data = data.get('data', {})
            merchant_no = product_data.get('channel', {}).get('channelNo')
            origin_product_no = product_data.get('productNo')
            
            if merchant_no and origin_product_no:
                print(f"âœ… ì •ë³´ íšë“ ì„±ê³µ! Merchant No: {merchant_no}, Product No: {origin_product_no}")
                return merchant_no, origin_product_no
            else:
                print("âŒ ì‘ë‹µì—ì„œ ìƒí’ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None, None
        except Exception as e:
            print(f"âŒ ëª¨ë°”ì¼ API ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return None, None

    def crawl_reviews_mobile(self):
        merchant_no, origin_product_no = self.get_product_info_mobile()
        if not merchant_no or not origin_product_no:
            return None
        
        all_reviews = []
        page = 1
        print("ğŸ“± ëª¨ë°”ì¼ APIë¡œ ë¦¬ë·° í¬ë¡¤ë§ ì‹œì‘...")

        while True:
            try:
                self._mobile_delay()
                url = MOBILE_ENDPOINTS['reviews_v1'].format(product_id=origin_product_no) + f"?page={page}&size=20"
                headers = self._get_mobile_headers(referer_url=f"https://m.smartstore.naver.com/products/{origin_product_no}")
                
                response = self.session.get(url, headers=headers, timeout=25)
                response.raise_for_status()
                data = response.json()
                
                reviews = data.get('contents', [])
                if not reviews:
                    print(f"âœ… ëª¨ë“  ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ (ì´ {len(all_reviews)}ê°œ)")
                    break
                
                for review in reviews:
                    option_contents = review.get('productOptionContents', [])
                    option_text = " / ".join([opt.get('optionContent', '') for opt in option_contents])
                    all_reviews.append({
                        'id': review.get('id'),
                        'rating': review.get('reviewScore'),
                        'writer': review.get('writerMemberId'),
                        'date': review.get('createDate'),
                        'content': review.get('reviewContent', ''),
                        'option': option_text,
                    })
                
                print(f"ğŸ“„ í˜ì´ì§€ {page}: {len(reviews)}ê°œ ë¦¬ë·° ìˆ˜ì§‘ (ì´ {len(all_reviews)}ê°œ)")
                page += 1
            
            except Exception as e:
                print(f"âŒ í˜ì´ì§€ {page} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}. í¬ë¡¤ë§ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                break

        return pd.DataFrame(all_reviews) if all_reviews else None

if __name__ == '__main__':
    print("ğŸ“± === ëª¨ë°”ì¼ ë„¤ì´ë²„ í¬ë¡¤ëŸ¬ ì‹œì‘ ===")
    print(f"ğŸ¯ íƒ€ê²Ÿ ìƒí’ˆ: {PRODUCT_ID}")
    
    crawler = MobileNaverCrawler(PRODUCT_ID)
    review_df = crawler.crawl_reviews_mobile()
    
    if review_df is not None and not review_df.empty:
        print("\nğŸ“Š === ë°ì´í„° ë¶„ì„ ì‹œì‘ ===")
        positive_keywords = ['ì¢‹ì•„ìš”', 'ë§Œì¡±', 'ì¶”ì²œ', 'ìµœê³ ', 'ë¹ ë¥¸', 'í¸í•˜ê³ ', 'ì˜ˆë»ìš”']
        negative_keywords = ['ë¶ˆí¸', 'ë³„ë¡œ', 'ì‹¤ë§', 'ì•„ì‰¬', 'ë¶ˆë§Œ', 'ëŠë¦°', 'ë¬´ê±°']
        
        review_df['sentiment'] = review_df['content'].apply(lambda x: analyze_sentiment(x, positive_keywords, negative_keywords))
        review_df = topic_modeling(review_df, NUM_TOPICS)
        
        review_df.to_csv(OUTPUT_FILE_NAME, index=False, encoding='utf-8-sig')
        print(f"\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ê°€ '{OUTPUT_FILE_NAME}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâŒ === í¬ë¡¤ë§ ì‹¤íŒ¨ ===")