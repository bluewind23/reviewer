"""
ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ í¬ë¡¤ëŸ¬ ì›¹ GUI
Flask ê¸°ë°˜ ì›¹ ì¸í„°í˜ì´ìŠ¤
"""
from flask import Flask, render_template, request, jsonify, send_from_directory
import os
import threading
import time
from datetime import datetime
import logging
import uuid
from smart_scheduler import SmartCrawlerScheduler

# --- Flask ì•± ì„¤ì • ---
app = Flask(__name__, static_folder='static')
# í™˜ê²½ë³€ìˆ˜ì—ì„œ ì‹œí¬ë¦¿ í‚¤ë¥¼ ê°€ì ¸ì˜¤ê³ , ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
# í„°ë¯¸ë„ì—ì„œ `export FLASK_SECRET_KEY='your-secret-key'`ë¡œ ì„¤ì •í•˜ì„¸ìš”.
app.secret_key = os.environ.get('FLASK_SECRET_KEY', 'default-secret-key-for-development')

# --- ê¸€ë¡œë²Œ ë³€ìˆ˜ ---
scheduler = SmartCrawlerScheduler()
crawl_jobs = {}
jobs_lock = threading.Lock() # ì‘ì—… ë”•ì…”ë„ˆë¦¬ ì ‘ê·¼ì„ ìœ„í•œ Lock

# --- ë¡œê¹… ì„¤ì • ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- ë¼ìš°íŒ… ---
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/static/<path:filename>')
def serve_static(filename):
    return send_from_directory(app.static_folder, filename)

@app.route('/api/extract_product_id', methods=['POST'])
def extract_product_id():
    data = request.get_json()
    url = data.get('url', '').strip()
    if not url:
        return jsonify({'success': False, 'error': 'URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'}), 400
    
    product_id = scheduler.extract_product_id(url)
    if product_id:
        return jsonify({'success': True, 'message': f'ìƒí’ˆ ID {product_id}ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.'})
    else:
        return jsonify({'success': False, 'error': 'URLì—ì„œ ìƒí’ˆ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ë„¤ì´ë²„ ì‡¼í•‘ URLì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.'})

@app.route('/api/start_crawl', methods=['POST'])
def start_crawl():
    data = request.get_json()
    url = data.get('url', '').strip()
    if not url:
        return jsonify({'success': False, 'error': 'URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'}), 400
    
    job_id = str(uuid.uuid4())
    with jobs_lock:
        crawl_jobs[job_id] = {
            'status': 'starting', 'progress': 0, 'message': 'í¬ë¡¤ë§ì„ ì¤€ë¹„ì¤‘ì…ë‹ˆë‹¤...',
            'url': url, 'name': data.get('name', '').strip(),
            'crawler': data.get('crawler', 'auto'), 'start_time': datetime.now().isoformat(),
            'result': None, 'error': None
        }
    
    thread = threading.Thread(target=run_crawl_job, args=(job_id, url, data.get('name'), data.get('crawler')))
    thread.daemon = True
    thread.start()
    
    return jsonify({'success': True, 'job_id': job_id})

@app.route('/api/job_status/<job_id>')
def job_status(job_id):
    with jobs_lock:
        job = crawl_jobs.get(job_id)
    if job:
        return jsonify({'success': True, 'job': job})
    else:
        return jsonify({'success': False, 'error': 'ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404

@app.route('/api/products', methods=['GET'])
def get_products():
    return jsonify({'success': True, 'products': scheduler.list_products()})

@app.route('/api/add_product', methods=['POST'])
def add_product():
    data = request.get_json()
    url = data.get('url', '').strip()
    if not url: return jsonify({'success': False, 'error': 'URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'}), 400
    
    if scheduler.add_product(url, data.get('name', '')):
        return jsonify({'success': True, 'message': 'ìƒí’ˆì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.'})
    else:
        return jsonify({'success': False, 'error': 'ìƒí’ˆ ì¶”ê°€ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. URLì„ í™•ì¸í•´ì£¼ì„¸ìš”.'})

@app.route('/api/remove_product/<product_id>', methods=['DELETE'])
def remove_product(product_id):
    if scheduler.remove_product(product_id):
        return jsonify({'success': True, 'message': 'ìƒí’ˆì´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.'})
    else:
        return jsonify({'success': False, 'error': 'ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404

@app.route('/api/settings', methods=['GET', 'POST'])
def settings():
    if request.method == 'POST':
        data = request.get_json()
        # ì—¬ê¸°ì— ì„¤ì • ì €ì¥ ë¡œì§ ì¶”ê°€ (VPN, ìŠ¤ì¼€ì¤„ ë“±)
        # ì˜ˆ: scheduler.setup_vpn(...) or scheduler.setup_schedule(...)
        return jsonify({'success': True, 'message': 'ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.'})
    else: # GET
        return jsonify({'success': True, 'settings': scheduler.config})

@app.route('/api/vpn_status', methods=['GET'])
def vpn_status():
    status = scheduler.get_vpn_status()
    return jsonify({'success': True, 'status': status, 'enabled': scheduler.config.get("vpn", {}).get("enabled")})


# --- ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ---
def run_crawl_job(job_id, url, name, crawler_type):
    job = crawl_jobs[job_id]
    
    def update_job(status, progress, message, error=None, result=None):
        with jobs_lock:
            job['status'] = status
            job['progress'] = progress
            job['message'] = message
            if error: job['error'] = error
            if result: job['result'] = result

    try:
        update_job('extracting', 10, 'URLì—ì„œ ìƒí’ˆ IDë¥¼ ì¶”ì¶œì¤‘ì…ë‹ˆë‹¤...')
        product_id = scheduler.extract_product_id(url)
        if not product_id:
            raise ValueError('URLì—ì„œ ìƒí’ˆ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        
        # VPN ì—°ê²° ë¡œì§ì€ scheduler.crawl_product ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë¨
        
        update_job('crawling', 30, f'{crawler_type} í¬ë¡¤ëŸ¬ë¡œ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...')
        
        # ì„ì‹œ ìƒí’ˆ ê°ì²´ ìƒì„±
        temp_product = {
            "id": product_id, "name": name or f"ì¦‰ì‹œí¬ë¡¤ë§_{product_id}",
            "url": url
        }
        
        # íŠ¹ì • í¬ë¡¤ëŸ¬ ë˜ëŠ” ìë™ í¬ë¡¤ëŸ¬ ì‹¤í–‰
        # crawl_productê°€ ë‚´ë¶€ì ìœ¼ë¡œ VPN ì—°ê²°/í•´ì œ ë° ë‹¤ì¤‘ í¬ë¡¤ëŸ¬ë¥¼ ì‹œë„í•¨
        if crawler_type != 'auto':
            scheduler.config['crawlers']['priority_order'] = [crawler_type]
        
        result_file = scheduler.crawl_product(temp_product)
        
        if result_file:
            update_job('completed', 100, 'í¬ë¡¤ë§ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!', result=result_file)
        else:
            raise Exception("ëª¨ë“  í¬ë¡¤ëŸ¬ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë‚˜ ìƒí’ˆ URLì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            
    except Exception as e:
        logger.error(f"í¬ë¡¤ë§ ì‘ì—…(job_id: {job_id}) ì˜¤ë¥˜: {e}")
        update_job('failed', 100, 'í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.', error=str(e))


# --- ì•± ì‹¤í–‰ ---
if __name__ == '__main__':
    # templates í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    if not os.path.exists('templates'):
        os.makedirs('templates')
    # static í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    if not os.path.exists('static'):
        os.makedirs('static')

    print("ğŸŒ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ í¬ë¡¤ëŸ¬ ì›¹ GUI ì‹œì‘")
    print("ğŸ”— ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:9090 ìœ¼ë¡œ ì ‘ì†í•˜ì„¸ìš”")
    print("â›” ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”")
    app.run(host='0.0.0.0', port=9090, debug=False)